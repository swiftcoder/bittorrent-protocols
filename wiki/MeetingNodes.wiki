Notes are sorted in reverse chronologically order. i.e Most recent first. 

== 03/11/10 ==
{{{ 
1) Tommy presented some techniques on generating models of upload capacities. 

   Continuous Distributions. 
      1. Lognormal
      2. Exponential
      3. Pareto
      4. Loggama
      5. Weibull
 
   Discreet Distributions. 
      1. Bipolar distributions.
      2. 80% of nodes get X from uniform distributions and 20% get Y from uniform distribution. 


   The significance of creating those distributions is to see whether the variance in simulation converge or not. Tristam reported that Mustfa tried to use bipolar distributions in the simulation and got unstable results. Mustfa results indicate that the variance doesn't converge. I will re-investage this problem.

2) One of the main objective is to understand the effects of selfish behavior protocols. 

3) Honggang has a theoretical model that claims the variance of selfish-behavior protocols  will eventually converge. 

4) Tommy presented the absolute non-selfish random protocol. During the wake-up period, a node randomly chooses a new set of upload nodes independent from the past. The variance of this protocol is around the 800 range but it fluctuates as time goes on. 

5) The question of whether can the variance goes to 0 is still unclear. 

}}}

== 02/25/10 ==
 Meeting canceled 

== 02/18/10 ==
{{{
1) Tristam presented his slides on download rates, variance, and minimum variance.

2) Tommy presented his hill climbing local search minimum algorithm.
  
3) Honggang proposed to let the nodes randomly choose N nodes to fill up their upload links. The argument is that the system total upload capacity is equally distributed to all nodes in the simulation. 
  
4) Tristam implemented the simple random algorithm and hill climbing   algorithm.
  
5) Tristam reported that the hill climbing algorithm produces a variance of 2103.
  
6) Tristam reported that the random algorithm produces the smallest observed variance of 1305. 
  
7) All slides are uploaded to the repository. 
  
8) We are planning to use this protocol/algorithm for streaming-bittorent-behavior. 

Attendance: Dan, Tristam, Honggang, Tommy
}}}

== 02/11/10 ==

{{{
1) Discussed on data dumping. Having mechanism to select what information to dump in the simulation. 

2) Went over the new "merged" code and redid previous simulations. Sanity check for the "merged" code. 

3) Duplex connection. A <-> B counts as two connections in the simulation.

4) Practical applications like video streaming where high upload-capacity nodes don't
really care about "donating" their bandwidth if they can stream at a typical rate. Fairness isn't the concern for high upload-capacity nodes if they can stream the video at a decent rate. Therefore minimizing the variance is a crucial part of the protocol. 

5) Ratio of  (# of connections / # of connections in a fully connected simulation)

6) CDF of generated distributions in log-scale.

7) Komogrove-Smirnove Test to see if generated distributions are correct.

8) Search for empirical data on the typical download rate of a bittorent streaming application

9) An optimization problem. How to minimizing the variance of the download rate by determining on 1) who to upload and 2) how much to upload. An algorithm that determines 
a node's upload peers and a decides on how much to upload to each peer. The constraint #1 is that the upload peers can "exit" out of the application. Therefore the fully connected network is dynamic. The constraint #2 is that each node makes selfish decisions to reach the maximum streaming rate potential. 
Attendance: Dan, Tristam, Honggang, Tommy
}}}


== 02/03/10 ==

{{{

1) Take ownership of new code and all code.

2) Re-reproduce all previous results Tristam and Mustafa Starting with the 2009 report.

3) Take notes in the meeting.

7) New formula for number of connections.

8) Google Repository for CODE & Notes

9) New formula for upper-bound.

10) Read the report.

11) We redefine the "losely" formula for the upperbound. 
     Constrains 1) Min link is 5kb
	        2) Cannot exceed n(n-1)/2

                 min((n-1, UPC/5) Sum of that (1/2)

12) Why do care about minimizing the variance? Because in the future we like to analyse
the different p2p protocols and compare the overall system performance of all nodes versus 
the individual performance of a single node. For example, all nodes make selfish decisions 
to maximize their download rates. How does the system behave when all users are selfish?

Attendance: Tommy, Dan, Honggang

}}}